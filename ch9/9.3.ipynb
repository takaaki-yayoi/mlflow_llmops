{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スーパーバイザー型マルチエージェントシステムの構築 - MLflow & LangGraph Tutorial\n",
    "\n",
    "## 概要\n",
    "このノートブックでは、複数の専門エージェントが協調して複雑なタスクを遂行する「スーパーバイザー型マルチエージェントシステム」を構築します。技術レポート作成という実践的なユースケースを通じて、エージェント設計、協調パターン、評価手法を学びます。\n",
    "\n",
    "### 学習内容\n",
    "1. マルチエージェントシステムの設計パターン（スーパーバイザー型）\n",
    "2. 専門化されたエージェントの実装（リサーチ、構成、執筆、レビュー）\n",
    "3. MLflow ResponseAgentによる標準インターフェース化\n",
    "4. 多様な評価手法（Safety、Guidelines、カスタムスコアラー、Agent-as-a-Judge）\n",
    "5. トレースベースの品質分析\n",
    "\n",
    "### スーパーバイザー型アーキテクチャとは？\n",
    "\n",
    "**従来の単一エージェント**\n",
    "- 1つのLLMがすべてのタスクを担当\n",
    "- 複雑なタスクでは品質が低下\n",
    "\n",
    "**スーパーバイザー型マルチエージェント**\n",
    "- 各エージェントが専門領域に特化\n",
    "- スーパーバイザーが全体を調整し、適切なエージェントに仕事を割り当て\n",
    "- 段階的な処理により高品質な出力を実現\n",
    "\n",
    "### 本ノートブックのエージェント構成\n",
    "\n",
    "1. **リサーチエージェント**: テーマの調査とポイント整理\n",
    "2. **構成エージェント**: レポート構成と見出しの決定\n",
    "3. **ライティングエージェント**: 本文の執筆\n",
    "4. **レビューエージェント**: 品質チェックと修正\n",
    "5. **スーパーバイザー**: 処理フローの制御と次のエージェントの決定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ1: 環境セットアップ\n",
    "\n",
    "### 必要なライブラリ\n",
    "- `mlflow`: 実験管理、モデル記録、トレーシング、評価\n",
    "- `langchain[openai]`: LangChainとOpenAI連携\n",
    "- `langgraph`: マルチエージェントワークフローの構築\n",
    "- `litellm`: 複数のLLMプロバイダーへの統一インターフェース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mlflow langchain[openai] langgraph litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ2: 認証情報の設定\n",
    "\n",
    "OpenAI APIを使用するため、APIキーを環境変数に設定します。\n",
    "\n",
    "**重要**: \n",
    "- `YOUR_API_KEY`を実際のAPIキーに置き換えてください\n",
    "- 本番環境では、シークレット管理サービスを使用することを推奨します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ3: マルチエージェントシステムの実装\n",
    "\n",
    "### アーキテクチャの詳細\n",
    "\n",
    "#### 共有状態（AgentState）\n",
    "すべてのエージェントが参照・更新する共通のデータ構造です。\n",
    "- `topic`: レポートのテーマ\n",
    "- `research_notes`: リサーチエージェントの出力\n",
    "- `outline`: 構成エージェントの出力\n",
    "- `draft`: ライティングエージェントの出力\n",
    "- `review_comments`: レビューエージェントのコメント\n",
    "- `final_report`: 最終的なレポート\n",
    "- `next_agent`: スーパーバイザーが決定する次の担当エージェント\n",
    "\n",
    "#### 処理フロー\n",
    "```\n",
    "START → Supervisor → Research Agent → Supervisor\n",
    "                   → Outline Agent → Supervisor\n",
    "                   → Writer Agent → Supervisor\n",
    "                   → Review Agent → Supervisor → END\n",
    "```\n",
    "\n",
    "### エージェント設計のポイント\n",
    "\n",
    "**専門化**\n",
    "- 各エージェントは1つの明確な役割のみを担当\n",
    "- プロンプトは役割に特化した指示を含む\n",
    "\n",
    "**状態の受け渡し**\n",
    "- 前のエージェントの出力を次のエージェントの入力として利用\n",
    "- スーパーバイザーが状態を確認し、次のステップを判断\n",
    "\n",
    "**トレーサビリティ**\n",
    "- MLflow Tracingで各エージェントの処理を記録\n",
    "- デバッグや品質分析が容易"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./multi_agent_report_app.py\n",
    "\"\"\"\n",
    "スーパーバイザー型マルチエージェントによる技術レポート作成アプリケーションです。\n",
    "\n",
    "エージェントの役割:\n",
    "  - リサーチエージェント: テーマについて調査し、ポイントを箇条書きで整理\n",
    "  - 構成エージェント: 見出し構成と各見出しの要点を決定\n",
    "  - ライティングエージェント: 構成に沿って本文を執筆\n",
    "  - レビューエージェント: レポート案をチェックし、必要なら修正を提案\n",
    "\n",
    "スーパーバイザー:\n",
    "  - 全体を調整し、各エージェントに順番に仕事を振り分ける\n",
    "\n",
    "MLflow ResponseAgent:\n",
    "  - システム全体をResponseAgentでラッピングし、標準的なインターフェースで公開します。\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "import functools\n",
    "\n",
    "import mlflow\n",
    "from mlflow.entities import SpanType\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# ==========\n",
    "# 事前準備\n",
    "# ==========\n",
    "\n",
    "# LLM（全エージェント共通）\n",
    "# temperature=0.2で適度な創造性を保ちつつ、一貫性のある出力を実現\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "# LangChain/MLflowの自動ロギングを有効化\n",
    "# LLM呼び出しやエージェント実行を自動的にMLflowに記録\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "\n",
    "# ==========\n",
    "# 状態の定義\n",
    "# ==========\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    エージェント間で受け渡す情報をまとめた共有状態です。\n",
    "    \n",
    "    この状態はワークフロー全体を通じて維持され、\n",
    "    各エージェントが必要な情報を読み取り、自分の出力を書き込みます。\n",
    "    \"\"\"\n",
    "    topic: str              # レポートのテーマ\n",
    "    research_notes: str     # リサーチ結果（箇条書き）\n",
    "    outline: str            # レポート構成（見出しと要点）\n",
    "    draft: str              # レポート本文（初稿）\n",
    "    review_comments: str    # レビューコメント\n",
    "    final_report: str       # 最終レポート（修正済み）\n",
    "    next_agent: str         # スーパーバイザーが決定する次のエージェント名\n",
    "\n",
    "\n",
    "# ==========\n",
    "# 各エージェントノードの実装\n",
    "# ==========\n",
    "\n",
    "def create_agent_node(agent_name: str, system_prompt: str):\n",
    "    \"\"\"\n",
    "    エージェントノードを作成するファクトリー関数です。\n",
    "    \n",
    "    このパターンにより、コードの重複を避け、\n",
    "    各エージェントの設定を一元管理できます。\n",
    "    \n",
    "    Args:\n",
    "        agent_name: エージェントの識別名\n",
    "        system_prompt: エージェントの役割と指示を定義するプロンプト\n",
    "    \n",
    "    Returns:\n",
    "        エージェントノード関数\n",
    "    \"\"\"\n",
    "    def agent_node(state: AgentState) -> AgentState:\n",
    "        \"\"\"エージェントの処理を実行し、状態を更新します。\"\"\"\n",
    "        # 状態から必要な情報を取り出す\n",
    "        topic = state.get(\"topic\", \"\")\n",
    "        research = state.get(\"research_notes\", \"\")\n",
    "        outline = state.get(\"outline\", \"\")\n",
    "        draft = state.get(\"draft\", \"\")\n",
    "\n",
    "        # エージェントごとに異なる入力を構築\n",
    "        # 各エージェントは前段階の出力を入力として受け取る\n",
    "        if agent_name == \"research_agent\":\n",
    "            user_content = f\"テーマ: {topic}\"\n",
    "        elif agent_name == \"outline_agent\":\n",
    "            user_content = f\"テーマ: {topic}\\n\\nリサーチ結果:\\n{research}\"\n",
    "        elif agent_name == \"writer_agent\":\n",
    "            user_content = f\"テーマ: {topic}\\n\\n構成案:\\n{outline}\"\n",
    "        elif agent_name == \"review_agent\":\n",
    "            user_content = f\"レポートドラフト:\\n{draft}\"\n",
    "        else:\n",
    "            user_content = \"\"\n",
    "\n",
    "        # LLMを呼び出し\n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=user_content),\n",
    "        ]\n",
    "        response = llm.invoke(messages)\n",
    "        result = response.content\n",
    "\n",
    "        # 結果を状態に保存\n",
    "        # 各エージェントは自分の担当フィールドのみを更新\n",
    "        if agent_name == \"research_agent\":\n",
    "            state[\"research_notes\"] = result\n",
    "        elif agent_name == \"outline_agent\":\n",
    "            state[\"outline\"] = result\n",
    "        elif agent_name == \"writer_agent\":\n",
    "            state[\"draft\"] = result\n",
    "        elif agent_name == \"review_agent\":\n",
    "            # レビュー結果を解析して、コメントと最終レポートに分割\n",
    "            if \"【修正後レポート案】\" in result:\n",
    "                comments, final = result.split(\"【修正後レポート案】\", maxsplit=1)\n",
    "                state[\"review_comments\"] = comments.strip()\n",
    "                state[\"final_report\"] = final.strip()\n",
    "            else:\n",
    "                state[\"review_comments\"] = result\n",
    "                state[\"final_report\"] = draft  # 修正不要の場合は原稿をそのまま使用\n",
    "\n",
    "        # トレースにプレビューを記録（後で分析しやすくするため）\n",
    "        mlflow.update_current_trace(tags={\n",
    "            f\"{agent_name}_preview\": result[:100],  # 最初の100文字のみ\n",
    "        })\n",
    "\n",
    "        return state\n",
    "\n",
    "    return agent_node\n",
    "\n",
    "\n",
    "# 4つの専門エージェントを作成\n",
    "# 各エージェントは明確な役割と具体的な出力形式を持つ\n",
    "\n",
    "research_node = create_agent_node(\n",
    "    \"research_agent\",\n",
    "    \"あなたは技術リサーチ担当です。テーマについて重要なポイントを箇条書きで5〜7個挙げてください。\"\n",
    ")\n",
    "\n",
    "outline_node = create_agent_node(\n",
    "    \"outline_agent\",\n",
    "    \"あなたは技術レポートの構成を考える担当です。リサーチメモをもとに、見出し構成（3〜5個）と各見出しの要点を番号付きで出力してください。\"\n",
    ")\n",
    "\n",
    "writer_node = create_agent_node(\n",
    "    \"writer_agent\",\n",
    "    \"あなたは技術レポートの執筆担当です。構成案に従って、各見出しごとに2〜4文程度で本文を書いてください。専門用語は平易な言葉で説明してください。\"\n",
    ")\n",
    "\n",
    "review_node = create_agent_node(\n",
    "    \"review_agent\",\n",
    "    \"あなたは技術レポートのレビュー担当です。技術的な正確さ、構成のわかりやすさ、文体をチェックし、【コメント】と【修正後レポート案】の形式で出力してください。\"\n",
    ")\n",
    "\n",
    "\n",
    "# ==========\n",
    "# スーパーバイザーノード\n",
    "# ==========\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    【スーパーバイザー: ワークフローの制御塔】\n",
    "    \n",
    "    現在の状態を確認し、次にどのエージェントを呼ぶかを決定します。\n",
    "    \n",
    "    判断ロジック（順次処理）:\n",
    "    1. リサーチ結果がない → research_agent\n",
    "    2. 構成案がない → outline_agent\n",
    "    3. 本文がない → writer_agent\n",
    "    4. 最終レポートがない → review_agent\n",
    "    5. すべて完了 → FINISH\n",
    "    \"\"\"\n",
    "    # 状態を見て、次に呼ぶべきエージェントを判断\n",
    "    if not state.get(\"research_notes\"):\n",
    "        next_agent = \"research_agent\"\n",
    "    elif not state.get(\"outline\"):\n",
    "        next_agent = \"outline_agent\"\n",
    "    elif not state.get(\"draft\"):\n",
    "        next_agent = \"writer_agent\"\n",
    "    elif not state.get(\"final_report\"):\n",
    "        next_agent = \"review_agent\"\n",
    "    else:\n",
    "        next_agent = \"FINISH\"\n",
    "\n",
    "    state[\"next_agent\"] = next_agent\n",
    "\n",
    "    # トレースに判断結果を記録\n",
    "    mlflow.update_current_trace(tags={\n",
    "        \"next_agent\": next_agent,\n",
    "    })\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "# ==========\n",
    "# グラフの構築\n",
    "# ==========\n",
    "\n",
    "def build_graph():\n",
    "    \"\"\"\n",
    "    スーパーバイザー型のマルチエージェントグラフを構築します。\n",
    "    \n",
    "    グラフ構造:\n",
    "    - 中央にスーパーバイザーを配置\n",
    "    - 各エージェントはスーパーバイザーから呼び出され、完了後にスーパーバイザーに戻る\n",
    "    - スーパーバイザーが次のエージェントを決定（条件分岐）\n",
    "    \"\"\"\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # 5つのノードを追加（スーパーバイザー + 4つの専門エージェント）\n",
    "    workflow.add_node(\"supervisor\", supervisor_node)\n",
    "    workflow.add_node(\"research_agent\", research_node)\n",
    "    workflow.add_node(\"outline_agent\", outline_node)\n",
    "    workflow.add_node(\"writer_agent\", writer_node)\n",
    "    workflow.add_node(\"review_agent\", review_node)\n",
    "\n",
    "    # 開始点: まずスーパーバイザーから開始\n",
    "    workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "    # スーパーバイザーの判断に基づいて分岐\n",
    "    def route_supervisor(state: AgentState) -> Literal[\"research_agent\", \"outline_agent\", \"writer_agent\", \"review_agent\", \"__end__\"]:\n",
    "        \"\"\"スーパーバイザーの決定に基づいて次のノードを返す\"\"\"\n",
    "        next_agent = state.get(\"next_agent\", \"FINISH\")\n",
    "        if next_agent == \"FINISH\":\n",
    "            return END\n",
    "        return next_agent\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"supervisor\",\n",
    "        route_supervisor,\n",
    "        {\n",
    "            \"research_agent\": \"research_agent\",\n",
    "            \"outline_agent\": \"outline_agent\",\n",
    "            \"writer_agent\": \"writer_agent\",\n",
    "            \"review_agent\": \"review_agent\",\n",
    "            END: END,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # 各エージェント実行後は、必ずスーパーバイザーに戻る（固定エッジ）\n",
    "    # これにより、スーパーバイザーが次のステップを制御できる\n",
    "    for agent in [\"research_agent\", \"outline_agent\", \"writer_agent\", \"review_agent\"]:\n",
    "        workflow.add_edge(agent, \"supervisor\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "# グラフを構築\n",
    "graph = build_graph()\n",
    "\n",
    "\n",
    "# ==========\n",
    "# ResponseAgentでラッピング\n",
    "# ==========\n",
    "\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    "    output_to_responses_items_stream,\n",
    "    to_chat_completions_input,\n",
    ")\n",
    "from typing import Generator\n",
    "\n",
    "class MultiAgentResponsesAgent(ResponsesAgent):\n",
    "    \"\"\"\n",
    "    マルチエージェントシステムをResponsesAgentでラッピングします。\n",
    "    \n",
    "    ResponsesAgentとは？\n",
    "    - MLflowが提供する標準的なエージェントインターフェース\n",
    "    - OpenAI互換のAPI形式でサービング可能\n",
    "    - ストリーミングと非ストリーミングの両方に対応\n",
    "    \n",
    "    メリット:\n",
    "    - 既存のチャットアプリケーションとの統合が容易\n",
    "    - REST API、Python、CLI等、複数の方法で呼び出し可能\n",
    "    - MLflowの評価・モニタリング機能と統合\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        \"\"\"\n",
    "        非ストリーミング版の予測メソッド。\n",
    "        ResponsesAgentRequestを受け取り、マルチエージェントを実行します。\n",
    "        \n",
    "        Args:\n",
    "            request: OpenAI互換の入力リクエスト\n",
    "        \n",
    "        Returns:\n",
    "            ResponsesAgentResponse: 最終レポートを含むレスポンス\n",
    "        \"\"\"\n",
    "        # ストリーミング版を実行して、完了イベントだけを集める\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "\n",
    "        return ResponsesAgentResponse(\n",
    "            output=outputs,\n",
    "            custom_outputs=request.custom_inputs\n",
    "        )\n",
    "\n",
    "    def predict_stream(\n",
    "        self, request: ResponsesAgentRequest\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        \"\"\"\n",
    "        ストリーミング版の予測メソッド。\n",
    "        各エージェントの出力をリアルタイムで返すことも可能ですが、\n",
    "        ここでは最終結果のみを返す実装としています。\n",
    "        \n",
    "        Args:\n",
    "            request: OpenAI互換の入力リクエスト\n",
    "        \n",
    "        Yields:\n",
    "            ResponsesAgentStreamEvent: ストリーミングイベント\n",
    "        \"\"\"\n",
    "        # RequestをChatCompletions形式に変換\n",
    "        messages = to_chat_completions_input([i.model_dump() for i in request.input])\n",
    "\n",
    "        # ユーザーの質問からトピックを抽出\n",
    "        topic = messages[-1][\"content\"] if messages else \"\"\n",
    "\n",
    "        # グラフに渡す初期状態を作成\n",
    "        initial_state = AgentState(\n",
    "            topic=topic,\n",
    "            research_notes=\"\",\n",
    "            outline=\"\",\n",
    "            draft=\"\",\n",
    "            review_comments=\"\",\n",
    "            final_report=\"\",\n",
    "            next_agent=\"\",\n",
    "        )\n",
    "\n",
    "        # グラフを実行（すべてのエージェントが順次実行される）\n",
    "        final_state = self.graph.invoke(initial_state)\n",
    "\n",
    "        # 最終レポートを出力として返す\n",
    "        final_report = final_state.get(\"final_report\", \"\")\n",
    "\n",
    "        yield ResponsesAgentStreamEvent(\n",
    "            type=\"response.output_item.done\",\n",
    "            item=self.create_text_output_item(\n",
    "                text=final_report,\n",
    "                id=\"final_report\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "# エージェントをインスタンス化してMLflowに登録\n",
    "agent = MultiAgentResponsesAgent(graph)\n",
    "mlflow.models.set_model(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ4: マルチエージェントシステムの実行とテスト\n",
    "\n",
    "構築したマルチエージェントシステムに実際にレポート作成を依頼します。\n",
    "\n",
    "### ResponsesAgentRequestの形式\n",
    "OpenAI ChatCompletions APIと互換性のある形式です。\n",
    "- `type`: メッセージタイプ（\"message\"）\n",
    "- `role`: 役割（\"user\", \"assistant\", \"system\"）\n",
    "- `content`: メッセージ内容（テキストや画像など）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from multi_agent_report_app import agent\n",
    "\n",
    "# レポート作成のリクエスト\n",
    "question = \"RAGに関する技術レポートを書いてください\"\n",
    "\n",
    "# ResponsesAgentRequestの形式\n",
    "# OpenAI互換のメッセージ形式\n",
    "input_data = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"input_text\", \"text\": question}]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# エージェントを実行\n",
    "# 内部で research → outline → writer → review と順次実行される\n",
    "response = agent.predict(input_data)\n",
    "\n",
    "# 最終レポートを取得\n",
    "final_report = response.output[0].content[0][\"text\"]\n",
    "\n",
    "print(\"質問：\", question)\n",
    "print(\"\\n最終レポート：\")\n",
    "print(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ5: ワークフローの可視化\n",
    "\n",
    "マルチエージェントシステムの構造を可視化します。\n",
    "\n",
    "### 可視化で確認できること\n",
    "- スーパーバイザーと各エージェントの関係\n",
    "- 条件分岐の構造\n",
    "- 処理の循環パターン（エージェント → スーパーバイザー → 次のエージェント）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from multi_agent_report_app import graph\n",
    "\n",
    "try:\n",
    "    # エージェントのグラフ構造を可視化（Mermaid形式）\n",
    "    graph_image = graph.get_graph().draw_mermaid_png()\n",
    "    display(Image(graph_image))\n",
    "    print(\"✓ ワークフローの図を表示しました\")\n",
    "except Exception as e:\n",
    "    print(f\"図の表示に失敗しました: {e}\")\n",
    "    print(\"（この機能は環境によっては動作しない場合があります）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ6: MLflowへのモデル記録\n",
    "\n",
    "### PyFuncフレーバー\n",
    "ResponsesAgentはMLflowのPyFuncフレーバーとして記録できます。\n",
    "\n",
    "### メタデータの記録\n",
    "モデルと一緒に以下の情報も記録します：\n",
    "- **パラメータ**: エージェント数、スーパーバイザータイプ等\n",
    "- **タグ**: アーキテクチャタイプ、バージョン等\n",
    "- **入力例**: スキーマ推論とテスト用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# MLflowの設定（ローカルTrackingサーバーを想定）\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"agentic_rag_example\")\n",
    "\n",
    "# LangGraphで構築したマルチエージェントシステムをMLflowに記録\n",
    "with mlflow.start_run(run_name=\"multi-agent-report-v1\") as run:\n",
    "    # pyfuncフレーバーとして記録\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=\"./multi_agent_report_app.py\",\n",
    "        input_example=input_data,\n",
    "    )\n",
    "\n",
    "    # パラメータとタグを記録（後で検索・比較しやすくする）\n",
    "    mlflow.log_param(\"agent_count\", 4)\n",
    "    mlflow.log_param(\"supervisor_type\", \"sequential\")\n",
    "    mlflow.set_tag(\"architecture\", \"supervisor\")\n",
    "\n",
    "print(\"モデルURI:\", model_info.model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ7: モデルのロードと推論テスト\n",
    "\n",
    "記録したモデルを読み込み、推論が正しく動作することを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 記録したモデルを読み込む\n",
    "loaded = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "# テスト推論を実行\n",
    "response = loaded.predict(input_data)\n",
    "\n",
    "# 結果を取得\n",
    "final_report = response[\"output\"][0][\"content\"][0][\"text\"]\n",
    "print(\"推論結果:\")\n",
    "print(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ8: MLflow Evaluation - Safety評価\n",
    "\n",
    "### Safety評価とは？\n",
    "LLMの出力が安全で適切かを評価する指標です。\n",
    "\n",
    "### 評価観点\n",
    "- 有害なコンテンツの有無\n",
    "- 偏見や差別的表現\n",
    "- 不適切な言及\n",
    "\n",
    "### 使用シーン\n",
    "本番環境にデプロイする前の安全性チェックとして活用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "マルチエージェントシステムをMLflow Evaluationで評価する例です。\n",
    "まずはSafety（安全性）評価から始めます。\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import Safety\n",
    "\n",
    "# 1. 評価データセットを用意\n",
    "dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"question\": \"RAGに関するレポートを作成してください\",\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# 2. 予測関数を定義\n",
    "def predict_wrapper(question: str) -> str:\n",
    "    \"\"\"\n",
    "    MLflow Evaluationから呼び出される予測関数です。\n",
    "\n",
    "    Args:\n",
    "        question: レポートのテーマ\n",
    "\n",
    "    Returns:\n",
    "        生成されたレポート\n",
    "    \"\"\"\n",
    "    # ResponsesAgentRequestの形式\n",
    "    input_data = {\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": question}]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = loaded.predict(input_data)\n",
    "    final_report = response[\"output\"][0][\"content\"][0][\"text\"]\n",
    "    return final_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Safety評価の実行\n",
    "with mlflow.start_run():\n",
    "    results = mlflow.genai.evaluate(\n",
    "        data=dataset,\n",
    "        predict_fn=predict_wrapper,\n",
    "        scorers=[\n",
    "            Safety(model=\"openai:/gpt-3.5-turbo\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "print(\"安全性評価が完了しました。MLflow UIで結果を確認してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ9: MLflow Evaluation - Guidelinesベースの評価\n",
    "\n",
    "### Guidelinesスコアラーとは？\n",
    "自然言語で記述された評価基準に基づいて、LLMが出力を評価する仕組みです。\n",
    "\n",
    "### メリット\n",
    "- **カスタマイズ性**: ビジネス要件に合わせた独自の評価基準を設定可能\n",
    "- **可読性**: 評価基準が自然言語なので、非技術者でも理解しやすい\n",
    "- **柔軟性**: コードを書かずに評価基準を変更できる\n",
    "\n",
    "### 評価基準の例\n",
    "1. **トーン**: 丁寧でプロフェッショナルな文体か\n",
    "2. **理解しやすさ**: 明確で簡潔な説明か\n",
    "3. **禁止トピック**: 特定の内容が含まれていないか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.genai import scorers\n",
    "\n",
    "\"\"\"\n",
    "ガイドラインベースのLLMスコアラー\n",
    "\n",
    "ガイドラインは、合格/不合格条件として定義された自然言語基準を定義することで、\n",
    "評価を迅速かつ容易にカスタマイズできるように設計された強力なスコアラークラスです。\n",
    "ルール、スタイルガイド、情報の包含/除外への準拠チェックに最適です。\n",
    "\n",
    "ガイドラインには、ビジネス関係者への説明が容易であるという明確な利点があります\n",
    "（「アプリがこのルールセットを満たしているかどうかを評価しています」）。\n",
    "そのため、多くの場合、ドメインエキスパートが直接記述できます。\n",
    "\"\"\"\n",
    "\n",
    "# 自然言語で評価基準を定義\n",
    "tone = \"回答は終始、丁寧でプロフェッショナルさを保たねばならない。\"\n",
    "\n",
    "easy_to_understand = \"\"\"回答は明確かつ簡潔な言葉を用い、論理的に構成されなければなりません。\n",
    "専門用語の使用は避け、使用する場合は説明を加える必要があります。\"\"\"\n",
    "\n",
    "banned_topics = \"価格に関する具体的な数値が記載されていないこと\"\n",
    "\n",
    "# Guidelinesスコアラーを作成\n",
    "tone_scorer = scorers.Guidelines(\n",
    "    name=\"tone\", \n",
    "    model=\"openai:/gpt-3.5-turbo\",\n",
    "    guidelines=tone\n",
    ")\n",
    "\n",
    "easy_to_understand_scorer = scorers.Guidelines(\n",
    "    name=\"easy_to_understand\", \n",
    "    model=\"openai:/gpt-3.5-turbo\",\n",
    "    guidelines=easy_to_understand\n",
    ")\n",
    "\n",
    "banned_topics_scorer = scorers.Guidelines(\n",
    "    name=\"banned_topics\", \n",
    "    model=\"openai:/gpt-3.5-turbo\",\n",
    "    guidelines=banned_topics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレースベースの評価\n",
    "\n",
    "MLflowは、過去の実行トレースを直接評価できます。\n",
    "これにより、本番環境での実際の出力を事後的に評価することが可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価の実行例\n",
    "# 直近のトレースを取得\n",
    "traces = mlflow.search_traces(\n",
    "    max_results=1,\n",
    ")\n",
    "\n",
    "if traces.empty:\n",
    "    print(\"評価対象のトレースが見つかりません。\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# ガイドラインベースの評価を実行\n",
    "results = mlflow.genai.evaluate(\n",
    "    data=traces,\n",
    "    scorers=[tone_scorer, easy_to_understand_scorer, banned_topics_scorer],\n",
    ")\n",
    "\n",
    "print(\"自然言語ベースの評価が完了しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ10: カスタムスコアラー - エージェント網羅性評価\n",
    "\n",
    "### カスタムスコアラーとは？\n",
    "独自のロジックで評価を行うスコアラーです。\n",
    "\n",
    "### このスコアラーの目的\n",
    "マルチエージェントシステムで、期待されるすべてのエージェントが\n",
    "実際に呼び出されたかを確認します。\n",
    "\n",
    "### 実装のポイント\n",
    "- `@scorer`デコレータで関数をスコアラーとして登録\n",
    "- `Trace`オブジェクトからSpanを検索\n",
    "- `Feedback`オブジェクトでスコアと理由を返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "エージェント呼び出しの網羅性を評価するコードベースのカスタムScorerです。\n",
    "\n",
    "・トレースからSpanType.AGENTのスパンを抽出\n",
    "・実際に呼ばれたエージェント名のリストを取得\n",
    "・期待されるエージェントがすべて呼ばれたかを確認\n",
    "\"\"\"\n",
    "import mlflow\n",
    "from mlflow.entities import Feedback, Trace, SpanType\n",
    "from mlflow.genai import scorer\n",
    "import pandas as pd\n",
    "\n",
    "@scorer\n",
    "def agent_coverage(trace: Trace, expectations: dict) -> Feedback:\n",
    "    \"\"\"\n",
    "    想定通りのエージェントが呼ばれているかを評価します。\n",
    "\n",
    "    評価基準:\n",
    "    - 期待されるエージェントがすべて呼ばれた場合: スコア1.0\n",
    "    - 一部のエージェントが欠けている場合: 呼ばれた割合をスコアとする\n",
    "\n",
    "    Args:\n",
    "        trace: 評価対象のトレース\n",
    "        expectations: 期待される動作を定義した辞書\n",
    "\n",
    "    Returns:\n",
    "        Feedback: スコアと理由を含む評価結果\n",
    "    \"\"\"\n",
    "    # トレースからエージェントスパンを検索\n",
    "    agent_spans = trace.search_spans(span_type=SpanType.AGENT)\n",
    "\n",
    "    # 実際に呼び出されたエージェント名を抽出\n",
    "    invoked_agents = [span.name for span in agent_spans]\n",
    "\n",
    "    # 期待されるエージェントのリスト\n",
    "    expected_agents = expectations.get(\"expected_agents\", [])\n",
    "    if not expected_agents:\n",
    "        return Feedback(\n",
    "            value=1.0,\n",
    "            rationale=\"期待値が指定されていないため、評価をスキップしました。\"\n",
    "        )\n",
    "\n",
    "    # 網羅性を計算（期待されるエージェントのうち何%が呼ばれたか）\n",
    "    invoked_set = set(invoked_agents)\n",
    "    expected_set = set(expected_agents)\n",
    "    covered = invoked_set & expected_set\n",
    "    coverage_ratio = len(covered) / len(expected_set) if expected_set else 0\n",
    "\n",
    "    # 詳細な理由を生成\n",
    "    if coverage_ratio == 1.0:\n",
    "        rationale = f\"期待通り、すべてのエージェント {expected_agents} が呼び出されました。\"\n",
    "    else:\n",
    "        missing = expected_set - invoked_set\n",
    "        extra = invoked_set - expected_set\n",
    "        rationale = (\n",
    "            f\"エージェント網羅率: {coverage_ratio:.0%}\\n\"\n",
    "            f\"期待: {sorted(expected_agents)}\\n\"\n",
    "            f\"実際: {sorted(invoked_agents)}\\n\"\n",
    "        )\n",
    "        if missing:\n",
    "            rationale += f\"未呼び出し: {sorted(missing)}\\n\"\n",
    "        if extra:\n",
    "            rationale += f\"予期しない呼び出し: {sorted(extra)}\"\n",
    "\n",
    "    return Feedback(\n",
    "        value=coverage_ratio,\n",
    "        rationale=rationale.strip()\n",
    "    )\n",
    "\n",
    "# トレースから評価データを取得\n",
    "traces = mlflow.search_traces(\n",
    "    max_results=1,\n",
    ")\n",
    "\n",
    "if traces.empty:\n",
    "    print(\"評価対象のトレースが見つかりません。\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# 期待されるエージェントのリストを追加\n",
    "traces[\"expectations\"] = [{\n",
    "    \"expected_agents\": [\n",
    "        \"research_agent\",\n",
    "        \"outline_agent\",\n",
    "        \"writer_agent\",\n",
    "        \"review_agent\"\n",
    "    ]\n",
    "}] * len(traces)\n",
    "\n",
    "# 評価を実行\n",
    "results = mlflow.genai.evaluate(\n",
    "    data=traces,\n",
    "    scorers=[agent_coverage],\n",
    ")\n",
    "\n",
    "print(\"エージェント網羅性の評価が完了しました。MLflow UIで結果を確認してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ11: Agent-as-a-Judge評価\n",
    "\n",
    "### Agent-as-a-Judgeとは？\n",
    "LLMエージェントが評価者となり、複雑な評価基準に基づいて\n",
    "他のLLMの出力を評価する手法です。\n",
    "\n",
    "### 他の評価手法との違い\n",
    "\n",
    "| 手法 | 評価方法 | 適用範囲 |\n",
    "|------|----------|----------|\n",
    "| コードベース | ルールベースチェック | 限定的 |\n",
    "| Guidelinesベース | セマンティックなチェック | 中程度 |\n",
    "| Agent-as-a-Judge | 複雑な推論と総合判断 | 広範囲 |\n",
    "\n",
    "### このスコアラーの評価観点\n",
    "**エージェント間の協調性**を多角的に評価：\n",
    "1. リサーチ結果が構成案に適切に反映されているか\n",
    "2. 構成案が本文に適切に反映されているか\n",
    "3. レビューコメントが本文の内容と整合しているか\n",
    "4. 無駄な差し戻しや重複作業が発生していないか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Agent-based Scorer (aka. Agent-as-a-Judge)を使った評価の例です。\n",
    "\n",
    "MLflowでは、評価基準を自然言語で記述することで、\n",
    "エージェントが自動的にその基準に基づいて評価を行います。\n",
    "\"\"\"\n",
    "import mlflow\n",
    "from mlflow.genai.judges import make_judge\n",
    "from typing import Literal\n",
    "\n",
    "# 自然言語で評価基準を定義\n",
    "AGENT_COORDINATION_GUIDELINE = \"\"\"\n",
    "あなたは、マルチエージェントシステムの「エージェント間の協調性」を評価する役割です。\n",
    "以下の観点で {{ trace }} を評価し、スコア（1〜5の整数）と理由を返してください。\n",
    "\n",
    "評価観点:\n",
    "1. リサーチ結果が構成案に適切に反映されているか\n",
    "2. 構成案が本文に適切に反映されているか\n",
    "3. レビューコメントが本文の内容と整合しているか\n",
    "4. 無意味な差し戻しや重複作業が発生していないか\n",
    "\n",
    "スコアの基準:\n",
    "- 5: すべての観点で優れている\n",
    "- 4: ほとんどの観点で良好だが、軽微な改善点がある\n",
    "- 3: いくつかの観点で問題があるが、全体としては機能している\n",
    "- 2: 複数の観点で明確な問題がある\n",
    "- 1: エージェント間の連携が機能していない\n",
    "\"\"\"\n",
    "\n",
    "# Agent-as-a-Judgeスコアラーを作成\n",
    "agent_coordination_scorer = make_judge(\n",
    "    name=\"agent_coordination\",\n",
    "    instructions=AGENT_COORDINATION_GUIDELINE,\n",
    "    feedback_value_type=Literal[\"5\", \"4\", \"3\", \"2\", \"1\"],\n",
    "    # トレース全体を分析するため、モデルを指定\n",
    "    model=\"openai:/gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# トレースから評価データを取得\n",
    "traces = mlflow.search_traces(\n",
    "    max_results=1,\n",
    ")\n",
    "\n",
    "if traces.empty:\n",
    "    print(\"評価対象のトレースが見つかりません。\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# Agent-as-a-Judge評価を実行\n",
    "results = mlflow.genai.evaluate(\n",
    "    data=traces,\n",
    "    scorers=[agent_coordination_scorer],\n",
    ")\n",
    "\n",
    "print(\"エージェント協調性の評価が完了しました。MLflow UIで結果を確認してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "### このノートブックで学んだこと\n",
    "\n",
    "#### アーキテクチャ設計\n",
    "1. **スーパーバイザー型マルチエージェント**: 中央制御による効率的なタスク分割\n",
    "2. **エージェントの専門化**: 各エージェントが明確な役割を持つ設計\n",
    "3. **状態管理**: AgentStateによる情報の受け渡し\n",
    "4. **ResponsesAgent**: 標準インターフェースでのラッピング\n",
    "\n",
    "#### 評価手法の多様性\n",
    "1. **Safety評価**: 安全性の自動チェック\n",
    "2. **Guidelinesベース評価**: ビジネスルールの自然言語記述\n",
    "3. **カスタムスコアラー**: 独自ロジックによる評価（エージェント網羅性）\n",
    "4. **Agent-as-a-Judge**: 複雑な総合評価（協調性）\n",
    "\n",
    "#### MLflowの活用\n",
    "1. **Tracing**: 全エージェントの処理を詳細に記録\n",
    "2. **Model Registry**: バージョン管理とデプロイ準備\n",
    "3. **Evaluation**: 多角的な品質評価\n",
    "4. **タグとパラメータ**: 実験の整理と検索\n",
    "\n",
    "### スーパーバイザー型の利点\n",
    "\n",
    "- **品質向上**: 各段階で専門的な処理が可能\n",
    "- **デバッグ容易性**: 問題のあるエージェントを特定しやすい\n",
    "- **拡張性**: 新しいエージェントの追加が容易\n",
    "- **制御性**: スーパーバイザーで処理フローを柔軟に制御\n",
    "\n",
    "### 次のステップ\n",
    "\n",
    "#### 機能拡張\n",
    "- 並列処理: 独立したエージェントを同時実行\n",
    "- 動的ルーティング: LLMによる次エージェントの判断\n",
    "- エラーハンドリング: リトライ機能の追加\n",
    "- メモリ機能: 過去の実行結果を参照\n",
    "\n",
    "#### 評価の強化\n",
    "- より大規模な評価データセット\n",
    "- 人間による評価との比較\n",
    "- A/Bテストによるプロンプト最適化\n",
    "- 継続的評価パイプラインの構築\n",
    "\n",
    "#### 本番環境へのデプロイ\n",
    "- REST APIとしてのサービング\n",
    "- バッチ処理パイプラインの構築\n",
    "- モニタリングとアラート設定\n",
    "- コスト最適化（モデル選択、キャッシング）\n",
    "\n",
    "### 参考リソース\n",
    "\n",
    "- [LangGraph Multi-Agent Systems](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/)\n",
    "- [MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html)\n",
    "- [MLflow Evaluation for LLMs](https://mlflow.org/docs/latest/llms/llm-evaluate/index.html)\n",
    "- [MLflow ResponsesAgent](https://mlflow.org/docs/latest/llms/deployments/index.html)\n",
    "- [Agent-as-a-Judge Pattern](https://arxiv.org/abs/2410.10934)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ]
}