"""
ç¬¬8ç«  8.5.2: OpenTelemetry (OTLP) è¨­å®š

MLflow Tracingã‚’OpenTelemetryãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹è¨­å®šä¾‹ã§ã™ã€‚

é‡è¦: MLflowã¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å˜ä¸€ã®å®›å…ˆã«ã®ã¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
OTEL_EXPORTER_OTLP_ENDPOINTãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€
MLflow Tracking Serverã«ã¯ãƒˆãƒ¬ãƒ¼ã‚¹ãŒã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚Œã¾ã›ã‚“ã€‚
"""

import os


def setup_otlp_export(
    endpoint: str,
    service_name: str,
    protocol: str = "grpc",
    service_version: str = None,
    deployment_environment: str = None,
    service_namespace: str = None,
) -> None:
    """
    OTLP ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’è¨­å®š
    
    Args:
        endpoint: OTLPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (ä¾‹: "http://otel-collector:4317")
        service_name: ã‚µãƒ¼ãƒ“ã‚¹å
        protocol: ãƒ—ãƒ­ãƒˆã‚³ãƒ« ("grpc" or "http/protobuf")
        service_version: ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        deployment_environment: ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        service_namespace: ã‚µãƒ¼ãƒ“ã‚¹åå‰ç©ºé–“ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    """
    # OTLPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®è¨­å®š
    os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = endpoint
    os.environ["OTEL_EXPORTER_OTLP_PROTOCOL"] = protocol
    
    # ã‚µãƒ¼ãƒ“ã‚¹åã®è¨­å®š
    os.environ["OTEL_SERVICE_NAME"] = service_name
    
    # ãƒªã‚½ãƒ¼ã‚¹å±æ€§ã®æ§‹ç¯‰
    resource_attrs = []
    
    if service_version:
        resource_attrs.append(f"service.version={service_version}")
    if deployment_environment:
        resource_attrs.append(f"deployment.environment={deployment_environment}")
    if service_namespace:
        resource_attrs.append(f"service.namespace={service_namespace}")
    
    if resource_attrs:
        os.environ["OTEL_RESOURCE_ATTRIBUTES"] = ",".join(resource_attrs)
    
    print(f"OTLP export configured:")
    print(f"  Endpoint: {endpoint}")
    print(f"  Protocol: {protocol}")
    print(f"  Service: {service_name}")
    if resource_attrs:
        print(f"  Attributes: {', '.join(resource_attrs)}")
    
    print("\nâš ï¸  WARNING: MLflow UI will NOT show traces when OTLP is configured.")
    print("   Traces are exported only to the OTLP endpoint.")


def setup_otlp_for_datadog(
    service_name: str,
    dd_api_key: str = None,
    dd_site: str = "datadoghq.com",
) -> None:
    """
    Datadogå‘ã‘ã®OTLPè¨­å®š
    
    Args:
        service_name: ã‚µãƒ¼ãƒ“ã‚¹å
        dd_api_key: Datadog APIã‚­ãƒ¼ (ç’°å¢ƒå¤‰æ•°DD_API_KEYã‹ã‚‰ã‚‚å–å¾—å¯èƒ½)
        dd_site: Datadogã‚µã‚¤ãƒˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: datadoghq.com)
    """
    api_key = dd_api_key or os.environ.get("DD_API_KEY")
    if not api_key:
        raise ValueError("Datadog API key is required")
    
    # Datadog OTLP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    endpoint = f"https://trace.agent.{dd_site}:443"
    
    os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = endpoint
    os.environ["OTEL_EXPORTER_OTLP_PROTOCOL"] = "grpc"
    os.environ["OTEL_SERVICE_NAME"] = service_name
    
    # Datadogå›ºæœ‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼
    os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"DD-API-KEY={api_key}"
    
    print(f"Datadog OTLP export configured:")
    print(f"  Service: {service_name}")
    print(f"  Site: {dd_site}")


def setup_otlp_for_grafana_tempo(
    service_name: str,
    tempo_endpoint: str = "http://tempo:4317",
) -> None:
    """
    Grafana Tempoå‘ã‘ã®OTLPè¨­å®š
    
    Args:
        service_name: ã‚µãƒ¼ãƒ“ã‚¹å
        tempo_endpoint: Tempoã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    """
    setup_otlp_export(
        endpoint=tempo_endpoint,
        service_name=service_name,
        protocol="grpc",
    )


def setup_otlp_for_jaeger(
    service_name: str,
    jaeger_endpoint: str = "http://jaeger:4317",
) -> None:
    """
    Jaegerå‘ã‘ã®OTLPè¨­å®š
    
    Args:
        service_name: ã‚µãƒ¼ãƒ“ã‚¹å
        jaeger_endpoint: Jaegerã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    """
    setup_otlp_export(
        endpoint=jaeger_endpoint,
        service_name=service_name,
        protocol="grpc",
    )


def setup_otlp_via_collector(
    service_name: str,
    collector_endpoint: str = "http://otel-collector:4317",
    service_version: str = None,
    deployment_environment: str = "production",
) -> None:
    """
    OpenTelemetry CollectorçµŒç”±ã§ã®è¨­å®š
    
    Collectorã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€è¤‡æ•°ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«åŒæ™‚ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã§ãã¾ã™ã€‚
    
    Args:
        service_name: ã‚µãƒ¼ãƒ“ã‚¹å
        collector_endpoint: Collectorã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        service_version: ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        deployment_environment: ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒ
    """
    setup_otlp_export(
        endpoint=collector_endpoint,
        service_name=service_name,
        protocol="grpc",
        service_version=service_version,
        deployment_environment=deployment_environment,
        service_namespace="llm-apps",
    )
    
    print("\nğŸ“¡ Using OpenTelemetry Collector for multi-backend export.")
    print("   Configure the collector to forward traces to your backends.")


def disable_otlp_export() -> None:
    """
    OTLPã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ç„¡åŠ¹åŒ–ã—ã€MLflowã«æˆ»ã™
    """
    keys_to_remove = [
        "OTEL_EXPORTER_OTLP_ENDPOINT",
        "OTEL_EXPORTER_OTLP_PROTOCOL",
        "OTEL_EXPORTER_OTLP_HEADERS",
    ]
    
    for key in keys_to_remove:
        if key in os.environ:
            del os.environ[key]
    
    print("OTLP export disabled. Traces will be sent to MLflow Tracking Server.")


# GenAI Semantic Conventions
GENAI_SEMANTIC_CONVENTIONS = {
    # ã‚·ã‚¹ãƒ†ãƒ /ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
    "gen_ai.system": "LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ (openai, anthropic, etc.)",
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    "gen_ai.request.model": "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸãƒ¢ãƒ‡ãƒ«å",
    "gen_ai.request.temperature": "æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
    "gen_ai.request.max_tokens": "æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
    "gen_ai.request.top_p": "Top-Pãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    "gen_ai.response.model": "å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«",
    "gen_ai.response.id": "ãƒ¬ã‚¹ãƒãƒ³ã‚¹ID",
    "gen_ai.response.finish_reasons": "å®Œäº†ç†ç”±",
    
    # ä½¿ç”¨é‡
    "gen_ai.usage.input_tokens": "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
    "gen_ai.usage.output_tokens": "å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
}


def print_semantic_conventions():
    """GenAI Semantic Conventionsã‚’è¡¨ç¤º"""
    print("=== GenAI Semantic Conventions ===")
    for attr, desc in GENAI_SEMANTIC_CONVENTIONS.items():
        print(f"  {attr}: {desc}")


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    print("=== OTLP Setup Examples ===\n")
    
    # OpenTelemetry CollectorçµŒç”±
    # setup_otlp_via_collector(
    #     service_name="customer-support-bot",
    #     service_version="1.2.0",
    #     deployment_environment="production",
    # )
    
    # Datadogç›´æ¥
    # setup_otlp_for_datadog(
    #     service_name="customer-support-bot",
    #     dd_api_key="your-api-key",
    # )
    
    # Grafana Tempo
    # setup_otlp_for_grafana_tempo(
    #     service_name="customer-support-bot",
    # )
    
    # Semantic Conventions
    print_semantic_conventions()
